{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import pickle\n",
    "import plotly.express as px\n",
    "\n",
    "# 1. Chargement des donnÃ©es\n",
    "\n",
    "X_full = pd.read_parquet(\"dataset_full.parquet\") \n",
    "\n",
    "# 2. Chargement du modÃ¨le\n",
    "loaded_model = xgb.Booster()\n",
    "loaded_model.load_model(\"xgboost_v3.json\")\n",
    "\n",
    "print(f\"âœ… ModÃ¨le et {len(X_full)} entreprises chargÃ©s.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Ã‰TAPE A : PRÃ‰PARATION & PRÃ‰DICTION ---\n",
    "\n",
    "# 1. Copie pour ne pas modifier l'original\n",
    "X_input = X_full.copy()\n",
    "\n",
    "# 2. Feature Engineering (RecrÃ©ation des variables du modÃ¨le)\n",
    "if \"Economie sociale et solidaire unitÃ© lÃ©gale\" in X_input.columns:\n",
    "    X_input['is_ess'] = X_input[\"Economie sociale et solidaire unitÃ© lÃ©gale\"].map({'O': 1, 'N': 0}).fillna(0)\n",
    "\n",
    "# 3. One-Hot Encoding des secteurs\n",
    "if 'libelle_section_ape' in X_input.columns:\n",
    "    X_input = pd.get_dummies(X_input, columns=['libelle_section_ape'], prefix='APE')\n",
    "\n",
    "# 4. Alignement strict avec les attentes du modÃ¨le (Colonnes manquantes et ordre)\n",
    "for col in loaded_model.feature_names:\n",
    "    if col not in X_input.columns:\n",
    "        X_input[col] = 0\n",
    "\n",
    "X_input = X_input[loaded_model.feature_names]\n",
    "\n",
    "# 5. Calcul des prÃ©dictions brutes\n",
    "dmatrix_full = xgb.DMatrix(X_input)\n",
    "raw_preds = loaded_model.predict(dmatrix_full)\n",
    "\n",
    "# --- Ã‰TAPE B : SCORING ET ANALYSE MÃ‰TIER ---\n",
    "\n",
    "# 1. Calcul de l'Indice de Risque Global (0-100)\n",
    "risk_scores = pd.Series(raw_preds).rank(pct=True, ascending=False) * 100\n",
    "\n",
    "# 2. CrÃ©ation du DataFrame de rÃ©sultats consolidÃ©\n",
    "df_resultats = pd.DataFrame({\n",
    "    'SIREN': X_full[\"SIREN\"],\n",
    "    'DÃ©nomination': X_full[\"DÃ©nomination de l'unitÃ© lÃ©gale\"],\n",
    "    'Indice_Risque': risk_scores.values\n",
    "}, index=X_full.index)\n",
    "\n",
    "# 3. Fonction de calcul des probabilitÃ©s par horizon avec nettoyage\n",
    "def calculer_probabilites_propres(score):\n",
    "\n",
    "    p_1an = 1 / (1 + np.exp(-(score - 85) / 3))\n",
    "    p_2ans = 1 / (1 + np.exp(-(score - 70) / 5))\n",
    "    p_3ans = 1 / (1 + np.exp(-(score - 55) / 7))\n",
    "    \n",
    "    probas = []\n",
    "    for p in [p_1an, p_2ans, p_3ans]:\n",
    "        val = round(p * 100, 2)\n",
    "        probas.append(val if val >= 0.01 else 0.0)\n",
    "    return probas[0], probas[1], probas[2]\n",
    "\n",
    "# 4. Application des calculs d'horizons\n",
    "df_resultats['Prob_1an'], df_resultats['Prob_2ans'], df_resultats['Prob_3ans'] = zip(*df_resultats['Indice_Risque'].map(calculer_probabilites_propres))\n",
    "\n",
    "# 5. Attribution du Statut Expert\n",
    "df_resultats['Statut_Expert'] = pd.cut(\n",
    "    df_resultats['Indice_Risque'], \n",
    "    bins=[0, 55, 70, 85, 100], \n",
    "    labels=['ðŸŸ¢ SAIN', 'ðŸŸ¡ OBSERVATION', 'ðŸŸ  VIGILANCE', 'ðŸ”´ CRITIQUE'],\n",
    "    include_lowest=True\n",
    ")\n",
    "\n",
    "# 6. Affichage des rÃ©sultats prioritaires\n",
    "print(f\"âœ… Analyse terminÃ©e sur {len(df_resultats)} entreprises.\")\n",
    "cols_view = ['SIREN', 'DÃ©nomination', 'Indice_Risque', 'Prob_1an', 'Prob_2ans', 'Prob_3ans', 'Statut_Expert']\n",
    "display(df_resultats[cols_view].sort_values('Indice_Risque', ascending=False).head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 6. Affichage final (SANS DOUBLONS)\n",
    "print(\"âœ… Diagnostic de survie consolidÃ© terminÃ© (Chiffres nettoyÃ©s) !\")\n",
    "cols_view = ['SIREN', 'DÃ©nomination', 'Indice_Risque', 'Prob_1an', 'Prob_2ans', 'Prob_3ans', 'Statut_Expert']\n",
    "\n",
    "# On ajoute .drop_duplicates sur le SIREN pour ne garder qu'une ligne par entreprise\n",
    "df_propre = df_resultats[cols_view].drop_duplicates(subset=['SIREN'], keep='first')\n",
    "\n",
    "# Affichage des 10 moins risquÃ©s (puisque tu fais tail sur un tri descendant)\n",
    "display(df_propre.sort_values('Indice_Risque', ascending=False).tail(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_propre.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projet-business",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
