{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test GPU par XGBoost\n",
    "try:\n",
    "    # On cr√©e une micro-matrice de test\n",
    "    data = xgb.DMatrix([[1, 2], [3, 4]], label=[1, 0])\n",
    "\n",
    "    params = {'tree_method': 'gpu_hist', 'device': 'cuda'}\n",
    "    xgb.train(params, data, num_boost_round=1)\n",
    "    print(\"‚úÖ Succ√®s ! La RTX 4060 est reconnue et configur√©e.\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå √âchec du GPU : {e}\")\n",
    "    print(\"Le mod√®le tournera sur CPU par d√©faut.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('dataset_full.parquet')\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 10)\n",
    "pd.set_option('display.float_format', '{:.4f}'.format)\n",
    "\n",
    "print(f\"Structure du dataset : {df.shape[0]} lignes et {df.shape[1]} colonnes\")\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "#### Import mod√®le et v√©rifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Chargement\n",
    "final_model = xgb.Booster()\n",
    "final_model.load_model(\"model_survie_V3_final.json\")\n",
    "\n",
    "# 2. Fouille r√©cursive du JSON\n",
    "def find_key(obj, key):\n",
    "    \"\"\"Cherche une cl√© n'importe o√π dans un dictionnaire ou une liste.\"\"\"\n",
    "    if isinstance(obj, dict):\n",
    "        for k, v in obj.items():\n",
    "            if k == key: return v\n",
    "            res = find_key(v, key)\n",
    "            if res is not None: return res\n",
    "    elif isinstance(obj, list):\n",
    "        for item in obj:\n",
    "            res = find_key(item, key)\n",
    "            if res is not None: return res\n",
    "    return None\n",
    "\n",
    "config = json.loads(final_model.save_config())\n",
    "model_scale = find_key(config, 'aft_loss_distribution_scale')\n",
    "\n",
    "if model_scale:\n",
    "    # XGBoost stocke souvent les valeurs en string dans le JSON\n",
    "    sigma_v3 = float(model_scale)\n",
    "    print(f\"üéØ Scale trouv√© dans le mod√®le : {sigma_v3}\")\n",
    "else:\n",
    "    # Si vraiment introuvable, on reprend ta valeur du Trial 26\n",
    "    sigma_v3 = 0.8011934962858392\n",
    "    print(f\"‚ö†Ô∏è Scale non trouv√© dans la config. Utilisation de la valeur manuelle : {sigma_v3}\")\n",
    "\n",
    "# 3. V√©rification des colonnes\n",
    "if final_model.feature_names:\n",
    "    print(f\"‚úÖ Colonnes configur√©es ({len(final_model.feature_names)})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "##### D√©finition de la fonction de survie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rappel de la fonction de calcul robuste\n",
    "def calculate_survival_risk(mu, horizon_annees, s=sigma_v3):\n",
    "    z = (np.log(horizon_annees) - mu) / s\n",
    "    z = np.clip(z, -50, 50)\n",
    "    return (1 / (1 + np.exp(-z))) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. FILTRAGE DU P√âRIM√àTRE (SOCI√âT√âS OUVERTES UNIQUEMENT) ---\n",
    "# On ne garde que les lignes o√π fermeture == 0\n",
    "df_vivantes = df[df['fermeture'] == 0].copy()\n",
    "\n",
    "# --- 2. CONFIGURATION DU MAPPING (4 CAT√âGORIES) ---\n",
    "def map_statut_expert_v3(p2):\n",
    "    if p2 > 20: return 'üî¥ CRITIQUE'\n",
    "    if p2 > 10: return 'üü† VIGILANCE'\n",
    "    if p2 > 5:  return 'üü° OBSERVATION'\n",
    "    return 'üü¢ SAIN'\n",
    "\n",
    "# --- 3. PR√âPARATION DES FEATURES SUR LE P√âRIM√àTRE FILTR√â ---\n",
    "df_inf = df_vivantes.copy()\n",
    "\n",
    "df_inf['age_au_diagnostic'] = pd.to_numeric(df_inf['age_estime'], errors='coerce').fillna(0)\n",
    "df_inf['Tranche_effectif_num'] = pd.to_numeric(df_inf['Tranche_effectif_num'], errors='coerce').fillna(0)\n",
    "df_inf['risque_departemental'] = pd.to_numeric(df_inf[\"Code du d√©partement de l'√©tablissement\"], errors='coerce').fillna(0)\n",
    "df_inf['is_ess'] = 0 \n",
    "\n",
    "if \"Cat√©gorie juridique de l'unit√© l√©gale\" in df_inf.columns:\n",
    "    df_inf['CJ_prefix'] = df_inf[\"Cat√©gorie juridique de l'unit√© l√©gale\"].astype(str).str[:4]\n",
    "    df_inf = pd.concat([df_inf, pd.get_dummies(df_inf['CJ_prefix'], prefix='CJ')], axis=1)\n",
    "\n",
    "if 'libelle_section_ape' in df_inf.columns:\n",
    "    df_ape_dummies = pd.get_dummies(df_inf['libelle_section_ape'], prefix='APE')\n",
    "    df_ape_dummies.columns = [c.strip() for c in df_ape_dummies.columns]\n",
    "    df_inf = pd.concat([df_inf, df_ape_dummies], axis=1)\n",
    "\n",
    "# --- 4. PR√âDICTION ---\n",
    "X_inf = pd.DataFrame(index=df_vivantes.index)\n",
    "for col in final_model.feature_names:\n",
    "    if col in df_inf.columns:\n",
    "        X_inf[col] = df_inf[col]\n",
    "    else:\n",
    "        match = [c for c in df_inf.columns if c.lower().strip() == col.lower().strip()]\n",
    "        X_inf[col] = df_inf[match[0]] if match else 0\n",
    "\n",
    "preds_mu = final_model.predict(xgb.DMatrix(X_inf.astype(float).fillna(0)))\n",
    "\n",
    "# --- 5. CR√âATION DU DATASET DASHBOARD ---\n",
    "df_dashboard = df_vivantes.copy()\n",
    "\n",
    "df_dashboard['Prob_1an']  = calculate_survival_risk(preds_mu, 1)\n",
    "df_dashboard['Prob_2ans'] = calculate_survival_risk(preds_mu, 2)\n",
    "df_dashboard['Prob_3ans'] = calculate_survival_risk(preds_mu, 3)\n",
    "\n",
    "df_dashboard['D√©nomination']  = df_vivantes[\"D√©nomination de l'unit√© l√©gale\"]\n",
    "df_dashboard['Indice_Risque']  = df_dashboard['Prob_2ans']\n",
    "df_dashboard['Statut_Expert']  = df_dashboard['Prob_2ans'].apply(map_statut_expert_v3)\n",
    "\n",
    "# --- 6. R√âORGANISATION ET EXPORT ---\n",
    "cols_ordre = [\n",
    "    'SIREN', 'D√©nomination', 'Statut_Expert', 'Indice_Risque', \n",
    "    'Prob_1an', 'Prob_2ans', 'Prob_3ans', \n",
    "    \"Code postal de l'√©tablissement\", \"Code commune de l'√©tablissement\",\n",
    "    \"Cat√©gorie juridique de l'unit√© l√©gale\", \"Activit√© principale de l'unit√© l√©gale\",\n",
    "    \"Economie sociale et solidaire unit√© l√©gale\", \"Code du d√©partement de l'√©tablissement\",\n",
    "    \"Code de la r√©gion de l'√©tablissement\", \"Date_fermeture_finale\",\n",
    "    \"Tranche_effectif_num\", \"age_estime\", \"latitude\", \"longitude\",\n",
    "    \"code_ape\", \"libelle_section_ape\", \"fermeture\"\n",
    "]\n",
    "\n",
    "df_dashboard = df_dashboard[[c for c in cols_ordre if c in df_dashboard.columns]]\n",
    "df_dashboard.to_parquet('Predictions_Risques_Survie_2026.parquet', index=False)\n",
    "\n",
    "print(f\"‚úÖ Analyse termin√©e sur les soci√©t√©s OUVERTES uniquement.\")\n",
    "print(f\"üìâ Soci√©t√©s √©cart√©es (d√©j√† ferm√©es) : {len(df) - len(df_dashboard)}\")\n",
    "print(f\"üìä Nouveau total √† analyser : {len(df_dashboard)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dashboard['Statut_Expert'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dashboard.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
